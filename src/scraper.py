import os
import re
import json
import hashlib
import datetime
from pathlib import Path
from bs4 import BeautifulSoup
import requests
from discord_webhook import DiscordWebhook
from dotenv import load_dotenv

class KaldiSaleScraper:
    def __init__(self, html_dir, target_shops=None, webhook_url=None, debug=False, history_file=None):
        """
        åˆæœŸåŒ–
        
        Args:
            html_dir: HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
            target_shops: å¯¾è±¡åº—èˆ—ãƒªã‚¹ãƒˆï¼ˆNoneã®å ´åˆã¯å…¨åº—èˆ—ï¼‰
            webhook_url: Discord Webhook URL
            debug: ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°
            history_file: é€šçŸ¥å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.html_dir = Path(html_dir)
        self.target_shops = target_shops
        self.webhook_url = webhook_url
        self.debug = debug
        self.history_file = Path(history_file) if history_file else Path("./data/notification_history.json")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
        os.makedirs(self.html_dir, exist_ok=True)
        os.makedirs(self.history_file.parent, exist_ok=True)
    
    def get_kaldi_url(self):
        """
        ç¾åœ¨ã®æ—¥ä»˜ã‚’ä½¿ç”¨ã—ãŸã‚«ãƒ«ãƒ‡ã‚£ã®URLç”Ÿæˆ
        
        Returns:
            ç”Ÿæˆã—ãŸURL
        """
        # ä»Šæ—¥ã®æ—¥ä»˜ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (yyyy-MM-dd)
        today = datetime.datetime.now().strftime("%Y-%m-%d")
        # åŸºæœ¬URLã«æ—¥ä»˜ã‚’è¿½åŠ 
        url = f"https://map.kaldi.co.jp/kaldi/articleList?account=kaldi&accmd=1&ftop=1&kkw001={today}"
        return url
        
    def get_date_from_url(self, url):
        """URLã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡ºã™ã‚‹
        
        Args:
            url: è§£æã™ã‚‹URL
            
        Returns:
            YYYYMMDDå½¢å¼ã®æ—¥ä»˜æ–‡å­—åˆ—ã€ã¾ãŸã¯æŠ½å‡ºã§ããªã„å ´åˆã¯None
        """
        try:
            # URLã‹ã‚‰æ—¥ä»˜éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆå½¢å¼: yyyy-MM-ddï¼‰
            match = re.search(r'kkw001=(\d{4}-\d{2}-\d{2})', url)
            if match:
                date_str = match.group(1)
                # ãƒã‚¤ãƒ•ãƒ³ã‚’é™¤å»ã—ã¦YYYYMMDDå½¢å¼ã«å¤‰æ›
                return date_str.replace('-', '')
            return None
        except Exception:
            return None
    
    def find_html_by_date(self, date):
        """æŒ‡å®šæ—¥ä»˜ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        
        Args:
            date: YYYYMMDDå½¢å¼ã®æ—¥ä»˜æ–‡å­—åˆ—
            
        Returns:
            è¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã€ã¾ãŸã¯è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯None
        """
        # æ—¥ä»˜ã‚’å«ã‚€HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        pattern = f"kaldi_sale_{date}*.html"
        for html_file in self.html_dir.glob(pattern):
            if self.debug:
                print(f"åŒã˜æ—¥ä»˜ã®æ—¢å­˜HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç™ºè¦‹: {html_file}")
            return html_file
        return None
    
    def fetch_and_save_html(self, url=None, force_fetch=False):
        """
        æŒ‡å®šURLã‹ã‚‰HTMLã‚’å–å¾—ã—ã¦ä¿å­˜
        
        Args:
            url: å–å¾—ã™ã‚‹URLï¼ˆNoneã®å ´åˆã¯è‡ªå‹•ç”Ÿæˆï¼‰
            force_fetch: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã£ã¦ã‚‚å¼·åˆ¶çš„ã«å–å¾—ã™ã‚‹ãƒ•ãƒ©ã‚°
            
        Returns:
            ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        try:
            # URLãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆ
            if url is None:
                url = self.get_kaldi_url()
                print(f"è‡ªå‹•ç”Ÿæˆã—ãŸURLã‚’ä½¿ç”¨ã—ã¾ã™: {url}")
            
            # URLã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º
            date = self.get_date_from_url(url)
            if date and not force_fetch:
                # åŒã˜æ—¥ä»˜ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
                existing_file = self.find_html_by_date(date)
                if existing_file:
                    print(f"åŒã˜æ—¥ä»˜({date})ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™: {existing_file}")
                    return existing_file
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆWebã‚µã‚¤ãƒˆã«ã‚ˆã£ã¦ã¯å¿…è¦ï¼‰
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            
            if self.debug:
                print(f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡: {url}")
                print(f"ãƒ˜ãƒƒãƒ€ãƒ¼: {headers}")
            
            # GETãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()  # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            
            if self.debug:
                print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
                print(f"ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼: {response.headers}")
                print(f"HTMLé•·ã•: {len(response.text)} ãƒã‚¤ãƒˆ")
            
            # æ—¥ä»˜ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«å«ã‚ã‚‹
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            # æ—¥ä»˜æƒ…å ±ãŒå–å¾—ã§ããŸå ´åˆã¯ãã‚Œã‚’ä½¿ã†
            prefix = date if date else timestamp[:8]
            filename = f"kaldi_sale_{prefix}_{timestamp[9:]}.html"
            filepath = self.html_dir / filename
            
            # HTMLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(response.text)
                
            print(f"HTMLã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            return filepath
            
        except requests.exceptions.RequestException as e:
            print(f"HTMLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            if self.debug:
                import traceback
                traceback.print_exc()
            return None
    
    def parse_html_files(self):
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ"""
        sales_info = []
        
        for html_file in self.html_dir.glob("*.html"):
            if self.debug:
                print(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«è§£æ: {html_file}")
                
            with open(html_file, "r", encoding="utf-8") as f:
                content = f.read()
            
            if self.debug:
                print(f"HTMLé•·ã•: {len(content)} ãƒã‚¤ãƒˆ")
                
            soup = BeautifulSoup(content, "html.parser")
            file_sales = self._extract_sales_info(soup)
            
            if self.debug:
                print(f"æŠ½å‡ºã•ã‚ŒãŸã‚»ãƒ¼ãƒ«æƒ…å ±æ•°: {len(file_sales)}")
                if len(file_sales) > 0:
                    print(f"æœ€åˆã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚µãƒ³ãƒ—ãƒ«: {file_sales[0]}")
                    
            sales_info.extend(file_sales)
        
        return sales_info
    
    def _extract_sales_info(self, soup):
        """
        BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰ã‚«ãƒ«ãƒ‡ã‚£ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’æŠ½å‡º
        """
        sales = []
        base_url = "https://map.kaldi.co.jp"
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã§åº—èˆ—ã”ã¨ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—
        sale_rows = soup.select("table.cz_sp_table tr")
        
        for row in sale_rows:
            # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚„ç©ºã®è¡Œã¯ç„¡è¦–
            if not row.select_one("td"):
                continue
            
            # åº—èˆ—æƒ…å ±ã‚’å«ã‚€tdã‚’å–å¾—
            shop_cell = row.select_one("td[aria-label='åº—èˆ—åã€ä½æ‰€ãªã©']")
            if not shop_cell:
                continue
                
            # ã‚»ãƒ¼ãƒ«å†…å®¹ã‚’å«ã‚€tdã‚’å–å¾—
            detail_cell = row.select_one("td[aria-label='ã‚»ãƒ¼ãƒ«å†…å®¹']")
            if not detail_cell:
                continue
            
            # åº—èˆ—å
            shop_name_elem = shop_cell.select_one("span.salename a")
            if not shop_name_elem:
                continue
                
            shop_name = shop_name_elem.text.strip()
            
            # å¯¾è±¡åº—èˆ—ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if self.target_shops and shop_name not in self.target_shops:
                continue
                
            # åº—èˆ—URL
            shop_url = base_url + shop_name_elem["href"] if shop_name_elem.has_attr("href") else ""
            
            # åº—èˆ—ä½æ‰€
            shop_address = shop_cell.select_one("span.saleadress").text.strip() if shop_cell.select_one("span.saleadress") else ""
            
            # ã‚»ãƒ¼ãƒ«ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆé–‹å‚¬ä¸­/äºˆå‘Šãªã©ï¼‰- é€šå¸¸ã¨äºˆå‘Šã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
            sale_status_elem = shop_cell.select_one("span.saleicon") or shop_cell.select_one("span.saleicon_f")
            sale_status = sale_status_elem.text.strip() if sale_status_elem else ""
            
            # ã‚»ãƒ¼ãƒ«ã‚¿ã‚¤ãƒˆãƒ« - é€šå¸¸ã¨äºˆå‘Šã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯
            sale_title_elem = shop_cell.select_one("span.saletitle") or shop_cell.select_one("span.saletitle_f")
            sale_title = sale_title_elem.text.strip() if sale_title_elem else ""
            
            # ã‚»ãƒ¼ãƒ«æœŸé–“ï¼ˆé€šå¸¸ã¨äºˆå‘Šã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            sale_date_elem = detail_cell.select_one("p.saledate") or detail_cell.select_one("p.saledate_f")
            sale_date = sale_date_elem.text.strip() if sale_date_elem else ""
            
            # ã‚»ãƒ¼ãƒ«è©³ç´°
            sale_detail = detail_cell.select_one("p.saledetail").text.strip() if detail_cell.select_one("p.saledetail") else ""
            
            # ã‚»ãƒ¼ãƒ«è©³ç´°ã®æ³¨æ„æ›¸ã
            sale_notes = detail_cell.select_one("p.saledetail_notes").text.strip() if detail_cell.select_one("p.saledetail_notes") else ""
            
            # è²©å£²æƒ…å ±ã‚’ã¾ã¨ã‚ã‚‹
            sales.append({
                "shop": shop_name,
                "address": shop_address,
                "status": sale_status,
                "title": sale_title,
                "date": sale_date,
                "detail": sale_detail,
                "notes": sale_notes,
                "url": shop_url
            })
        
        return sales
    
    def format_sale_message(self, sale):
        """ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’é€šçŸ¥ç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›"""
        return f"""
ğŸ”” {sale.get('status', 'æ–°ã‚»ãƒ¼ãƒ«')}!
ğŸ“ {sale.get('shop', 'ä¸æ˜')}
ğŸ¬ {sale.get('address', '')}
ğŸ¯ {sale.get('title', 'ã‚»ãƒ¼ãƒ«è©³ç´°ä¸æ˜')}
ğŸ“… {sale.get('date', 'æ—¥ä»˜ä¸æ˜')}
ğŸ’° {sale.get('detail', '')}
ğŸ”— {sale.get('url', '#')}
"""

    def save_to_text_file(self, sales_info, output_file="sales_output.txt"):
        """ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if not sales_info:
            return False
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºä¿
        output_path = Path(output_file)
        os.makedirs(output_path.parent, exist_ok=True)
        
        with open(output_file, "w", encoding="utf-8") as f:
            for sale in sales_info:
                message = self.format_sale_message(sale)
                f.write(message)
                f.write("\n" + "-"*40 + "\n")  # åŒºåˆ‡ã‚Šç·š
        
        return True
        
    def generate_sale_id(self, sale):
        """ã‚»ãƒ¼ãƒ«æƒ…å ±ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯IDç”Ÿæˆ
        
        Args:
            sale: ã‚»ãƒ¼ãƒ«æƒ…å ±è¾æ›¸
            
        Returns:
            ã‚»ãƒ¼ãƒ«ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ID
        """
        # é‡è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’é€£çµã—ã¦ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆ
        key_fields = [
            sale.get('shop', ''),
            sale.get('title', ''),
            sale.get('date', ''),
            sale.get('detail', '')
        ]
        
        hash_string = "|".join(key_fields)
        # SHA256ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆã—ã¦16é€²æ•°æ–‡å­—åˆ—ã§è¿”ã™
        return hashlib.sha256(hash_string.encode('utf-8')).hexdigest()
    
    def load_notification_history(self):
        """é€šçŸ¥å±¥æ­´ã®èª­ã¿è¾¼ã¿
        
        Returns:
            é€šçŸ¥å±¥æ­´ã®è¾æ›¸ï¼ˆã‚»ãƒ¼ãƒ«ID: é€šçŸ¥æ—¥æ™‚ï¼‰
        """
        if not self.history_file.exists():
            if self.debug:
                print(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.history_file}")
            return {}
            
        try:
            with open(self.history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
                
            if self.debug:
                print(f"é€šçŸ¥å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(history)}ä»¶")
                
            return history
        except (json.JSONDecodeError, IOError) as e:
            if self.debug:
                print(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return {}
    
    def save_notification_history(self, history):
        """é€šçŸ¥å±¥æ­´ã®ä¿å­˜
        
        Args:
            history: ä¿å­˜ã™ã‚‹é€šçŸ¥å±¥æ­´è¾æ›¸
        """
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, ensure_ascii=False, indent=2)
                
            if self.debug:
                print(f"é€šçŸ¥å±¥æ­´ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {len(history)}ä»¶")
                
        except IOError as e:
            if self.debug:
                print(f"å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def filter_new_sales(self, sales_info):
        """æ–°ã—ã„ã‚»ãƒ¼ãƒ«æƒ…å ±ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            sales_info: å…¨ã‚»ãƒ¼ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
            
        Returns:
            æœªé€šçŸ¥ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        # é€šçŸ¥å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
        history = self.load_notification_history()
        
        # æ–°ã—ã„ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        new_sales = []
        for sale in sales_info:
            sale_id = self.generate_sale_id(sale)
            
            # å±¥æ­´ã«ãªã„ã‚»ãƒ¼ãƒ«æƒ…å ±ã®ã¿ã‚’è¿½åŠ 
            if sale_id not in history:
                new_sales.append(sale)
                if self.debug:
                    print(f"æ–°ã—ã„ã‚»ãƒ¼ãƒ«æƒ…å ±: {sale.get('shop')} - {sale.get('title')}")
            else:
                if self.debug:
                    print(f"æ—¢ã«é€šçŸ¥æ¸ˆã¿: {sale.get('shop')} - {sale.get('title')}")
        
        return new_sales
    
    def update_notification_history(self, sales_info):
        """ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’é€šçŸ¥å±¥æ­´ã«è¿½åŠ 
        
        Args:
            sales_info: é€šçŸ¥ã—ãŸã‚»ãƒ¼ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
        """
        # é€šçŸ¥å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€
        history = self.load_notification_history()
        
        # ç¾åœ¨ã®æ—¥æ™‚
        now = datetime.datetime.now().isoformat()
        
        # æ–°ã—ã„é€šçŸ¥ã‚’å±¥æ­´ã«è¿½åŠ 
        for sale in sales_info:
            sale_id = self.generate_sale_id(sale)
            history[sale_id] = {
                "notified_at": now,
                "shop": sale.get('shop', ''),
                "title": sale.get('title', ''),
                "date": sale.get('date', '')
            }
        
        # å±¥æ­´ã‚’ä¿å­˜
        self.save_notification_history(history)
    
    def notify_discord(self, sales_info, update_history=False):
        """Discord Webhookã‚’ä½¿ç”¨ã—ã¦ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’é€šçŸ¥
        
        Args:
            sales_info: é€šçŸ¥ã™ã‚‹ã‚»ãƒ¼ãƒ«æƒ…å ±ãƒªã‚¹ãƒˆ
            update_history: é€šçŸ¥å±¥æ­´ã‚’æ›´æ–°ã™ã‚‹ã‹ã©ã†ã‹
        
        Returns:
            é€šçŸ¥æˆåŠŸã®å ´åˆã¯True
        """
        if not self.webhook_url or not sales_info:
            if self.debug:
                if not self.webhook_url:
                    print("Discordé€šçŸ¥: Webhook URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                if not sales_info:
                    print("Discordé€šçŸ¥: é€šçŸ¥ã™ã‚‹ã‚»ãƒ¼ãƒ«æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        if self.debug:
            print(f"Discordé€šçŸ¥: {len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’é€ä¿¡ã—ã¾ã™")
            # Webhookã®æœ€åˆã®æ•°æ–‡å­—ã‚’è¡¨ç¤ºï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®ãŸã‚å…¨éƒ¨ã¯è¡¨ç¤ºã—ãªã„ï¼‰
            webhook_prefix = self.webhook_url[:30] + "..." if len(self.webhook_url) > 30 else self.webhook_url
            print(f"Discord Webhook URL: {webhook_prefix}")
        
        for i, sale in enumerate(sales_info):
            message = self.format_sale_message(sale)
            
            if self.debug:
                print(f"Discordé€šçŸ¥ {i+1}/{len(sales_info)}: {sale.get('shop')} - {sale.get('title')}")
                
            webhook = DiscordWebhook(url=self.webhook_url, content=message)
            response = webhook.execute()
            
            if self.debug:
                print(f"Discordé€šçŸ¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ {response.status_code}")
            
            # APIåˆ¶é™ã‚’é¿ã‘ã‚‹ãŸã‚å°‘ã—å¾…æ©Ÿ
            if i < len(sales_info) - 1:
                import time
                time.sleep(1)
        
        # é€šçŸ¥å±¥æ­´æ›´æ–°ãƒ•ãƒ©ã‚°ãŒã‚ã‚Œã°é€šçŸ¥å±¥æ­´ã‚’æ›´æ–°
        if update_history:
            self.update_notification_history(sales_info)
            if self.debug:
                print(f"Discordé€šçŸ¥: {len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¾ã—ãŸ")
        
        return True

def main():
    import argparse
    
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    load_dotenv()
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®è¨­å®š
    parser = argparse.ArgumentParser(description='ã‚«ãƒ«ãƒ‡ã‚£ã‚»ãƒ¼ãƒ«æƒ…å ±å–å¾—ãƒ„ãƒ¼ãƒ«')
    parser.add_argument('--url', type=str, help='ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’å–å¾—ã™ã‚‹URLï¼ˆæŒ‡å®šã—ãªã„å ´åˆã¯ç¾åœ¨ã®æ—¥ä»˜ã§è‡ªå‹•ç”Ÿæˆï¼‰')
    parser.add_argument('--notify', action='store_true', help='Discordã«é€šçŸ¥ã™ã‚‹')
    parser.add_argument('--output', type=str, help='å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã‚’ä¸Šæ›¸ãã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: sales_output.txtï¼‰')
    parser.add_argument('--fetch-only', action='store_true', help='HTMLã®å–å¾—ã®ã¿ã‚’è¡Œã†')
    parser.add_argument('--no-fetch', action='store_true', help='HTMLã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è§£æ')
    parser.add_argument('--force-fetch', action='store_true', help='åŒã˜æ—¥ä»˜ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¦ã‚‚å¼·åˆ¶çš„ã«å–å¾—ã™ã‚‹')
    parser.add_argument('--shops', type=str, help='å¯¾è±¡åº—èˆ—ã®ãƒªã‚¹ãƒˆï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰')
    parser.add_argument('--all-shops', action='store_true', help='å…¨åº—èˆ—ã‚’å¯¾è±¡ã«ã™ã‚‹')
    parser.add_argument('--discord-webhook', type=str, help='Discord Webhook URLï¼ˆ.envãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šã‚’ä¸Šæ›¸ãï¼‰')
    parser.add_argument('--history-file', type=str, help='é€šçŸ¥å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ./data/notification_history.jsonï¼‰')
    parser.add_argument('--force-notify', action='store_true', help='é€šçŸ¥å±¥æ­´ã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«é€šçŸ¥ã™ã‚‹')
    parser.add_argument('--debug', action='store_true', help='ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆè©³ç´°æƒ…å ±ã‚’è¡¨ç¤ºï¼‰')
    args = parser.parse_args()
    
    # Discord Webhook URLã‚’å–å¾—ï¼ˆå„ªå…ˆé †ä½: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•° > ç’°å¢ƒå¤‰æ•°ï¼‰
    webhook_url = None
    if args.notify:
        webhook_url = args.discord_webhook or os.environ.get("DISCORD_WEBHOOK_URL")
    
    # å¯¾è±¡åº—èˆ—ãƒªã‚¹ãƒˆï¼ˆå„ªå…ˆé †ä½: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ > ç’°å¢ƒå¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
    if args.all_shops:
        target_shops = None  # ã™ã¹ã¦ã®åº—èˆ—ã‚’å¯¾è±¡
    elif args.shops:
        target_shops = [shop.strip() for shop in args.shops.split(',')]
    elif os.environ.get("TARGET_SHOPS"):
        target_shops = [shop.strip() for shop in os.environ.get("TARGET_SHOPS").split(',')]
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å¯¾è±¡åº—èˆ—ãƒªã‚¹ãƒˆ
        target_shops = ["æ± è¢‹åº—", "æ¸‹è°·åº—", "æ–°å®¿åº—", "ç«‹å·è‹¥è‘‰ã‚±ãƒ¤ã‚­ãƒ¢ãƒ¼ãƒ«åº—"]
    
    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®è¨­å®šï¼ˆã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ > ç’°å¢ƒå¤‰æ•°ï¼‰
    debug_mode = args.debug or os.environ.get("DEBUG") == "1"
    
    # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
    history_file = args.history_file or os.environ.get("HISTORY_FILE") or "./data/notification_history.json"
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
    scraper = KaldiSaleScraper(
        html_dir="./data",
        target_shops=target_shops,
        webhook_url=webhook_url,
        debug=debug_mode,
        history_file=history_file
    )
    
    # no-fetchã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯HTMLã‚’å–å¾—
    if not args.no_fetch:
        # force-fetchã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ¸¡ã—ã¦ã€åŒã˜æ—¥ä»˜ã®HTMLãŒå­˜åœ¨ã—ã¦ã‚‚å¼·åˆ¶å–å¾—ã™ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¶å¾¡
        html_path = scraper.fetch_and_save_html(args.url, force_fetch=args.force_fetch)
        if not html_path:
            print("HTMLã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return
        
        # fetch-onlyã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã“ã“ã§çµ‚äº†
        if args.fetch_only:
            return
    
    # ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’æŠ½å‡º
    sales_info = scraper.parse_html_files()
    if not sales_info:
        print("ã‚»ãƒ¼ãƒ«æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        return
        
    # æœªé€šçŸ¥ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã ã‘ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆ--force-notifyãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
    if not args.force_notify:
        new_sales = scraper.filter_new_sales(sales_info)
        if not new_sales:
            print("æ–°ã—ã„ã‚»ãƒ¼ãƒ«æƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ã™ã¹ã¦æ—¢ã«é€šçŸ¥æ¸ˆã¿ã§ã™ã€‚")
            return
        sales_info = new_sales
    else:
        print(f"å¼·åˆ¶å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚{len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’å‡¦ç†ã—ã¾ã™ã€‚")
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®šï¼ˆå„ªå…ˆé †ä½: ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚ªãƒ—ã‚·ãƒ§ãƒ³ > ç’°å¢ƒå¤‰æ•° > ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ï¼‰
    output_file = args.output or os.environ.get("OUTPUT_FILE") or "sales_output.txt"
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    scraper.save_to_text_file(sales_info, output_file)
    print(f"{len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’{output_file}ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    # å±¥æ­´ã«è¿½åŠ ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ™‚ã«é‡è¤‡æ’é™¤ã®ãŸã‚ï¼‰
    # --notify ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã‚‚å±¥æ­´ã«ã¯è¿½åŠ ã™ã‚‹
    if not args.force_notify:
        scraper.update_notification_history(sales_info)
        print(f"{len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¾ã—ãŸ")
    
    # Discordé€šçŸ¥ï¼ˆ--notifyã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒã‚ã‚‹å ´åˆã®ã¿ï¼‰
    if args.notify and webhook_url:
        # å±¥æ­´ã¯ã™ã§ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€update_history=Falseã‚’æŒ‡å®š
        scraper.notify_discord(sales_info, update_history=False)
        print(f"{len(sales_info)}ä»¶ã®ã‚»ãƒ¼ãƒ«æƒ…å ±ã‚’Discordã«é€šçŸ¥ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()